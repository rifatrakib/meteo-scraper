# meteo-scraper

This codebase contains a web scraper built with [Scrapy](https://scrapy.org/), an open source Python framework for web scraping, to collect historical weather data for more than a 1000 cities in China (or configurable with any other country, with a different count of cities) from [Open-Meteo](https://open-meteo.com/). The scraper is configured in a way that it obeys the complex rate limiting principles of the provider and also restarts the scraper as soon as the rate limiting constraints are lifted. The daily limits are not automated in the initial version of the project. The collected hourly weather data are stored in files named chronologically for each date which contains data about `temperature` (2 meters from surface), `relative humidity` (2 meters from surface), `dew point` (2 meters from surface), `apparent temperature`, `precipitation`, `rain`, `snowfall`, and `snow_depth`. For each request, data for 10 different cities are collected for each hour of a day and processed accordingly which costs 10 API calls for each request made. In case of the scraper terminating on account of rate limiting, the downloaded data for that day is not saved in the final storage, rather they are cached and the request cycle follows the following iteration of requests avoiding making the same request multiple times.
